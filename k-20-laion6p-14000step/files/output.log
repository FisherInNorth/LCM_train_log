
Checkpoint 'latest' does not exist. Starting a new training run.
08/14/2024 19:35:55 - INFO - __main__ - ***** Running training *****
08/14/2024 19:35:55 - INFO - __main__ -   Num batches each epoch = 5192
08/14/2024 19:35:55 - INFO - __main__ -   Num Epochs = 20
08/14/2024 19:35:55 - INFO - __main__ -   Instantaneous batch size per device = 16
08/14/2024 19:35:55 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32
08/14/2024 19:35:55 - INFO - __main__ -   Gradient Accumulation steps = 1
08/14/2024 19:35:55 - INFO - __main__ -   Total optimization steps = 100000
Steps:   0%|▏                                                                                          | 200/100000 [07:27<61:00:36,  2.20s/it, loss=0.0223, lr=8e-6]08/14/2024 19:43:22 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.54it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.28it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 19:43:26 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.32it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.01it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   0%|▎                                                                                          | 400/100000 [14:50<59:43:33,  2.16s/it, loss=0.0296, lr=8e-6]08/14/2024 19:50:45 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.45it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.12it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 19:50:49 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.44it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.11it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   1%|▌                                                                                            | 600/100000 [22:14<60:23:28,  2.19s/it, loss=0.02, lr=8e-6]08/14/2024 19:58:09 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.49it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.16it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 19:58:13 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.42it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.13it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   1%|▋                                                                                          | 800/100000 [29:38<60:07:03,  2.18s/it, loss=0.0231, lr=8e-6]08/14/2024 20:05:34 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.35it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.05it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 20:05:37 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.43it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.12it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   1%|▉                                                                                         | 1000/100000 [37:03<60:40:12,  2.21s/it, loss=0.0232, lr=8e-6]08/14/2024 20:12:58 - INFO - accelerate.accelerator - Saving current state to /data/hepengyu/trainingLCM/output/checkpoint-1000
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-1000/unet_target/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-1000/unet_target/diffusion_pytorch_model.safetensors
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-1000/unet/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-1000/unet/diffusion_pytorch_model.safetensors
08/14/2024 20:13:05 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-1000/optimizer.bin
08/14/2024 20:13:05 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-1000/scheduler.bin
08/14/2024 20:13:05 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-1000/scaler.pt
08/14/2024 20:13:05 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-1000/random_states_0.pkl
08/14/2024 20:13:05 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-1000
08/14/2024 20:13:05 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.18it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.58it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 20:13:08 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.17it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.58it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   1%|█                                                                                         | 1200/100000 [44:29<59:27:19,  2.17s/it, loss=0.0209, lr=8e-6]08/14/2024 20:20:25 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.91it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.40it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 20:20:28 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.00it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.43it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   1%|█▎                                                                                        | 1400/100000 [51:50<59:19:39,  2.17s/it, loss=0.0234, lr=8e-6]08/14/2024 20:27:45 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.08it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.54it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 20:27:49 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.30it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.73it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   2%|█▍                                                                                        | 1600/100000 [59:12<58:10:00,  2.13s/it, loss=0.0235, lr=8e-6]08/14/2024 20:35:07 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.98it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.42it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 20:35:11 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.41it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 12.87it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   2%|█▌                                                                                      | 1800/100000 [1:06:25<57:54:28,  2.12s/it, loss=0.0235, lr=8e-6]08/14/2024 20:42:20 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.51it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 12.97it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 20:42:24 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.84it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.28it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   2%|█▊                                                                                      | 2000/100000 [1:13:40<58:37:00,  2.15s/it, loss=0.0282, lr=8e-6]08/14/2024 20:49:35 - INFO - accelerate.accelerator - Saving current state to /data/hepengyu/trainingLCM/output/checkpoint-2000
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-2000/unet_target/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-2000/unet_target/diffusion_pytorch_model.safetensors
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-2000/unet/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-2000/unet/diffusion_pytorch_model.safetensors
08/14/2024 20:49:42 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-2000/optimizer.bin
08/14/2024 20:49:42 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-2000/scheduler.bin
08/14/2024 20:49:42 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-2000/scaler.pt
08/14/2024 20:49:42 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-2000/random_states_0.pkl
08/14/2024 20:49:42 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-2000
08/14/2024 20:49:42 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.19it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.58it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 20:49:45 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.07it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.49it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:40:50 - INFO - __main__ - Running validation...                                       | 2200/100000 [1:21:03<58:36:13,  2.16s/it, loss=0.0209, lr=8e-6]08/14/2024 20:56:59 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.33it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.74it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 20:57:02 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.34it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.77it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   2%|██▏                                                                                      | 2400/100000 [1:28:20<58:43:47,  2.17s/it, loss=0.023, lr=8e-6]08/14/2024 21:04:16 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.14it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.59it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:04:19 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.09it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.49it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   3%|██▎                                                                                      | 2600/100000 [1:35:37<58:14:16,  2.15s/it, loss=0.019, lr=8e-6]08/14/2024 21:11:32 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.12it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.57it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:11:36 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.29it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.73it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   3%|██▌                                                                                       | 2800/100000 [1:42:54<57:55:27,  2.15s/it, loss=0.04, lr=8e-6]08/14/2024 21:18:49 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.04it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.50it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:18:52 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.16it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.60it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   3%|██▋                                                                                     | 3000/100000 [1:50:11<57:39:31,  2.14s/it, loss=0.0204, lr=8e-6]08/14/2024 21:26:06 - INFO - accelerate.accelerator - Saving current state to /data/hepengyu/trainingLCM/output/checkpoint-3000
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-3000/unet_target/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-3000/unet_target/diffusion_pytorch_model.safetensors
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-3000/unet/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-3000/unet/diffusion_pytorch_model.safetensors
08/14/2024 21:26:12 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-3000/optimizer.bin
08/14/2024 21:26:12 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-3000/scheduler.bin
08/14/2024 21:26:12 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-3000/scaler.pt
08/14/2024 21:26:12 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-3000/random_states_0.pkl
08/14/2024 21:26:12 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-3000
08/14/2024 21:26:12 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.17it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.59it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:26:16 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.03it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.48it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   3%|██▊                                                                                     | 3200/100000 [1:57:35<57:36:42,  2.14s/it, loss=0.0203, lr=8e-6]08/14/2024 21:33:30 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.12it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.59it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:33:34 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.10it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.51it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   3%|██▉                                                                                     | 3400/100000 [2:04:51<57:20:24,  2.14s/it, loss=0.0223, lr=8e-6]08/14/2024 21:40:46 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.92it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.39it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:40:50 - INFO - __main__ - Running validation...                                       | 2200/100000 [1:21:03<58:36:13,  2.16s/it, loss=0.0209, lr=8e-6]08/14/2024 20:56:59 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.21it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.66it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   4%|███▏                                                                                    | 3600/100000 [2:12:08<57:12:36,  2.14s/it, loss=0.0157, lr=8e-6]08/14/2024 21:48:03 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.84it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.22it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:48:07 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.19it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.63it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   4%|███▎                                                                                    | 3800/100000 [2:19:26<58:15:53,  2.18s/it, loss=0.0234, lr=8e-6]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.57it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.11it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 21:55:25 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.97it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.43it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   4%|███▌                                                                                    | 4000/100000 [2:26:51<58:07:41,  2.18s/it, loss=0.0184, lr=8e-6]08/14/2024 22:02:46 - INFO - accelerate.accelerator - Saving current state to /data/hepengyu/trainingLCM/output/checkpoint-4000
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-4000/unet_target/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-4000/unet_target/diffusion_pytorch_model.safetensors
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-4000/unet/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-4000/unet/diffusion_pytorch_model.safetensors
08/14/2024 22:02:52 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-4000/optimizer.bin
08/14/2024 22:02:52 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-4000/scheduler.bin
08/14/2024 22:02:52 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-4000/scaler.pt
08/14/2024 22:02:52 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-4000/random_states_0.pkl
08/14/2024 22:02:52 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-4000
08/14/2024 22:02:52 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.16it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.55it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 22:02:56 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.16it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.58it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   4%|███▋                                                                                    | 4200/100000 [2:34:21<58:00:02,  2.18s/it, loss=0.0179, lr=8e-6]08/14/2024 22:10:17 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.16it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.62it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 22:10:20 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.23it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.64it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   4%|███▊                                                                                    | 4400/100000 [2:41:45<57:47:31,  2.18s/it, loss=0.0207, lr=8e-6]08/14/2024 22:17:40 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.73it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.25it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 22:17:44 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.05it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.47it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   5%|████                                                                                    | 4600/100000 [2:49:08<58:16:56,  2.20s/it, loss=0.0152, lr=8e-6]08/14/2024 22:25:03 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.16it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.61it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 22:25:07 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.11it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.58it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   5%|████▏                                                                                   | 4725/100000 [2:53:48<57:34:39,  2.18s/it, loss=0.0272, lr=8e-6]
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.18it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.61it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   5%|████▊                                                                                   | 5400/100000 [3:18:58<57:50:17,  2.20s/it, loss=0.0193, lr=8e-6]08/14/2024 22:54:53 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.23it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.66it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 22:54:57 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.98it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.42it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   6%|████▉                                                                                   | 5600/100000 [3:26:22<56:56:07,  2.17s/it, loss=0.0223, lr=8e-6]08/14/2024 23:02:17 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.05it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.48it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 23:02:21 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.16it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.58it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   6%|█████                                                                                   | 5800/100000 [3:33:46<57:06:28,  2.18s/it, loss=0.0256, lr=8e-6]08/14/2024 23:09:42 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.10it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.56it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 23:09:45 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.15it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.60it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   6%|█████▎                                                                                  | 6000/100000 [3:41:11<57:25:18,  2.20s/it, loss=0.0257, lr=8e-6]08/14/2024 23:17:07 - INFO - accelerate.accelerator - Saving current state to /data/hepengyu/trainingLCM/output/checkpoint-6000
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-6000/unet_target/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-6000/unet_target/diffusion_pytorch_model.safetensors
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-6000/unet/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-6000/unet/diffusion_pytorch_model.safetensors
08/14/2024 23:17:13 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-6000/optimizer.bin
08/14/2024 23:17:13 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-6000/scheduler.bin
08/14/2024 23:17:13 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-6000/scaler.pt
08/14/2024 23:17:13 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-6000/random_states_0.pkl
08/14/2024 23:17:13 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-6000
08/14/2024 23:17:13 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.26it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.69it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 23:17:18 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 12.50it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 11.97it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   6%|█████▍                                                                                  | 6200/100000 [3:48:43<56:50:43,  2.18s/it, loss=0.0257, lr=8e-6]08/14/2024 23:24:38 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.45it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 12.97it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 23:24:42 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.95it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.40it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-7000/unet/config.json██████████████████████████████████████████████| 7/7 [00:00<00:00, 14.18it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-7000/unet/diffusion_pytorch_model.safetensors
08/14/2024 23:54:19 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-7000/optimizer.bin
08/14/2024 23:54:19 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-7000/scheduler.bin
08/14/2024 23:54:19 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-7000/scaler.pt
08/14/2024 23:54:19 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-7000/random_states_0.pkl
08/14/2024 23:54:19 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-7000
08/14/2024 23:54:19 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.09it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.50it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/14/2024 23:54:24 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.19it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.64it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   7%|██████▍                                                                                  | 7200/100000 [4:25:49<56:02:51,  2.17s/it, loss=0.029, lr=8e-6]08/15/2024 00:01:44 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.09it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.53it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 00:01:48 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.07it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.55it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   7%|██████▌                                                                                 | 7400/100000 [4:33:13<56:32:03,  2.20s/it, loss=0.0207, lr=8e-6]08/15/2024 00:09:08 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.06it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.49it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 00:09:12 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.06it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.50it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   8%|██████▋                                                                                  | 7568/100000 [4:39:26<55:27:38,  2.16s/it, loss=0.021, lr=8e-6]
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.06it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.50it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   8%|███████▍                                                                                | 8400/100000 [5:10:19<55:04:39,  2.16s/it, loss=0.0168, lr=8e-6]08/15/2024 00:46:14 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.06it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.51it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 00:46:18 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.17it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.63it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   9%|███████▌                                                                                | 8600/100000 [5:17:42<55:37:38,  2.19s/it, loss=0.0168, lr=8e-6]08/15/2024 00:53:37 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.09it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.52it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 00:53:41 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.11it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.57it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   9%|███████▊                                                                                 | 8800/100000 [5:25:07<55:19:06,  2.18s/it, loss=0.024, lr=8e-6]08/15/2024 01:01:02 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.11it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.56it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 01:01:06 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.03it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.46it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:   9%|███████▉                                                                                | 9000/100000 [5:32:31<55:29:47,  2.20s/it, loss=0.0282, lr=8e-6]08/15/2024 01:08:26 - INFO - accelerate.accelerator - Saving current state to /data/hepengyu/trainingLCM/output/checkpoint-9000
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-9000/unet_target/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-9000/unet_target/diffusion_pytorch_model.safetensors
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-9000/unet/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-9000/unet/diffusion_pytorch_model.safetensors
08/15/2024 01:08:33 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-9000/optimizer.bin
08/15/2024 01:08:33 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-9000/scheduler.bin
08/15/2024 01:08:33 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-9000/scaler.pt
08/15/2024 01:08:33 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-9000/random_states_0.pkl
08/15/2024 01:08:33 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-9000
08/15/2024 01:08:33 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.07it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.47it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 01:08:36 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.44it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  10%|████████▋                                                                              | 10000/100000 [6:09:38<54:06:56,  2.16s/it, loss=0.0181, lr=8e-6]08/15/2024 01:45:33 - INFO - accelerate.accelerator - Saving current state to /data/hepengyu/trainingLCM/output/checkpoint-10000
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-10000/unet_target/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-10000/unet_target/diffusion_pytorch_model.safetensors
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-10000/unet/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-10000/unet/diffusion_pytorch_model.safetensors
08/15/2024 01:45:40 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-10000/optimizer.bin
08/15/2024 01:45:40 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-10000/scheduler.bin
08/15/2024 01:45:40 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-10000/scaler.pt
08/15/2024 01:45:40 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-10000/random_states_0.pkl
08/15/2024 01:45:40 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-10000
08/15/2024 01:45:40 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.11it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.52it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 01:45:45 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.13it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.57it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  10%|████████▊                                                                              | 10200/100000 [6:17:10<54:41:56,  2.19s/it, loss=0.0298, lr=8e-6]08/15/2024 01:53:06 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.08it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.54it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 01:53:09 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.98it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.41it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  10%|█████████                                                                              | 10400/100000 [6:24:35<54:19:57,  2.18s/it, loss=0.0276, lr=8e-6]08/15/2024 02:00:30 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.10it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.55it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 02:00:34 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.14it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.58it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  11%|█████████▏                                                                             | 10552/100000 [6:30:14<53:56:50,  2.17s/it, loss=0.0197, lr=8e-6]
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.83it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.30it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  11%|██████████                                                                              | 11400/100000 [7:01:42<53:32:49,  2.18s/it, loss=0.033, lr=8e-6]08/15/2024 02:37:37 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.71it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.20it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 02:37:41 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.01it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.44it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  12%|██████████                                                                             | 11514/100000 [7:05:58<53:43:15,  2.19s/it, loss=0.0177, lr=8e-6]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.37it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  12%|██████████▊                                                                            | 12400/100000 [7:38:49<53:18:19,  2.19s/it, loss=0.0156, lr=8e-6]08/15/2024 03:14:45 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.59it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.10it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 03:14:48 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.07it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.54it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  13%|██████████▉                                                                            | 12600/100000 [7:46:13<53:10:31,  2.19s/it, loss=0.0222, lr=8e-6]08/15/2024 03:22:08 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.65it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.15it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 03:22:12 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.84it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.29it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  13%|███████████▏                                                                           | 12800/100000 [7:53:36<52:43:03,  2.18s/it, loss=0.0214, lr=8e-6]08/15/2024 03:29:31 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.13it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.61it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 03:29:35 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.06it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.48it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  13%|███████████▎                                                                           | 13000/100000 [8:01:00<52:53:30,  2.19s/it, loss=0.0171, lr=8e-6]08/15/2024 03:36:55 - INFO - accelerate.accelerator - Saving current state to /data/hepengyu/trainingLCM/output/checkpoint-13000
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-13000/unet_target/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-13000/unet_target/diffusion_pytorch_model.safetensors
Configuration saved in /data/hepengyu/trainingLCM/output/checkpoint-13000/unet/config.json
Model weights saved in /data/hepengyu/trainingLCM/output/checkpoint-13000/unet/diffusion_pytorch_model.safetensors
08/15/2024 03:37:02 - INFO - accelerate.checkpointing - Optimizer state saved in /data/hepengyu/trainingLCM/output/checkpoint-13000/optimizer.bin
08/15/2024 03:37:02 - INFO - accelerate.checkpointing - Scheduler state saved in /data/hepengyu/trainingLCM/output/checkpoint-13000/scheduler.bin
08/15/2024 03:37:02 - INFO - accelerate.checkpointing - Gradient scaler state saved in /data/hepengyu/trainingLCM/output/checkpoint-13000/scaler.pt
08/15/2024 03:37:02 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-13000/random_states_0.pkl
08/15/2024 03:37:02 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-13000
08/15/2024 03:37:02 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.08it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.51it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 03:37:06 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.07it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.52it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  13%|███████████▍                                                                           | 13160/100000 [8:07:04<52:51:04,  2.19s/it, loss=0.0252, lr=8e-6]
08/15/2024 04:14:09 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-14000/random_states_0.pkl0:00, 13.37it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
08/15/2024 04:14:09 - INFO - __main__ - Saved state to /data/hepengyu/trainingLCM/output/checkpoint-14000
08/15/2024 04:14:09 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.84it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.34it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 04:14:13 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.04it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.49it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  14%|████████████▎                                                                          | 14200/100000 [8:45:39<51:34:42,  2.16s/it, loss=0.0268, lr=8e-6]08/15/2024 04:21:34 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.06it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.50it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 04:21:38 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 13.95it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.39it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  14%|████████████▌                                                                          | 14400/100000 [8:53:03<51:58:55,  2.19s/it, loss=0.0262, lr=8e-6]08/15/2024 04:28:58 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.15it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.57it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
08/15/2024 04:29:02 - INFO - __main__ - Running validation...
{'thresholding', 'timestep_spacing', 'clip_sample_range', 'timestep_scaling', 'dynamic_thresholding_ratio', 'sample_max_value', 'original_inference_steps', 'rescale_betas_zero_snr', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                     Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of /data/hepengyu/teachermodels/SD1-5.                       | 0/7 [00:00<?, ?it/s]
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of /data/hepengyu/teachermodels/SD1-5.
                                                                                                                                                                     Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of /data/hepengyu/teachermodels/SD1-5.
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.00it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.00<00:00, 13.44it/s]
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  15%|████████████▋                                                                          | 14532/100000 [8:57:59<52:07:10,  2.20s/it, loss=0.0191, lr=8e-6]
08/15/2024 04:14:09 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-14000/random_states_0.pkl0:00, 13.37it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...
08/15/2024 04:14:09 - INFO - accelerate.checkpointing - Random states saved in /data/hepengyu/trainingLCM/output/checkpoint-14000/random_states_0.pkl0:00, 13.37it/s]08/14/2024 21:55:21 - INFO - __main__ - Running validation...